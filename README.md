ğŸ”¥ S.U.E. â€” Sentient Unified Entity
Local Autonomous AI Assistant (llama.cpp Edition)

by Jedi Security

S.U.E. is a fully local, privacy-first autonomous AI system built to run on llama.cpp, with:

Local LLM responses (GGUF models)

Local vector memory (llama.cpp embeddings)

JSON-based long-term memory

RSS intelligence ingestion

PDF document ingestion + indexing

Dev Mode with secure sandbox execution

Systemd autostart for persistent background operation

No cloud dependencies, no telemetry, no external calls

S.U.E. is engineered to run entirely offline on Ubuntu, Windows, Termux (Android), WSL, and low-power hardware.

ğŸš€ Features
ğŸ§  Local LLM Core (llama.cpp)

Runs any GGUF model you choose

Supports 3Bâ€“70B models (CPU or GPU-optional)

No PyTorch or transformers required

Zero CUDA requirement (even works on older GPUs)

ğŸ“š Vector Memory (llama.cpp embedding API)

Embeds & stores user interactions

Searches memory using cosine similarity

Fast, simple, structured JSON database

Memory grows over time

ğŸ“° RSS Intelligence Ingestion

Auto-refreshes RSS feeds

Summarizes headlines

Stores digests into long-term memory

ğŸ“„ PDF Knowledge Ingestion

Extracts text from PDFs

Indexes every page as memory entries

Tagging support

ğŸ’» Dev Mode

Run shell commands in sandbox

Execute Python snippets safely

Perfect for OSINT, automation, scraping

ğŸ¨ Interactive CLI Dashboard

Rich console UI

Emotion-color reactions

Clean Matrix-style look

ğŸ”„ Cognitive Rebuild Mode

Cleans memory

Re-indexes logs

Ongoing self-maintenance

ğŸ”§ Autostarts at Boot

Full systemd service included

Automatic background operation

Crash recovery & restart

ğŸ“ Project Structure
SUE/
 â”œâ”€â”€ sue.py
 â”œâ”€â”€ install.sh
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ config/
 â”‚    â”œâ”€â”€ settings.json
 â”‚    â””â”€â”€ feeds.json
 â”œâ”€â”€ core/
 â”‚    â”œâ”€â”€ dispatcher.py
 â”‚    â”œâ”€â”€ memory_json.py
 â”‚    â”œâ”€â”€ memory_vector.py
 â”‚    â”œâ”€â”€ hallucination_filter.py
 â”‚    â”œâ”€â”€ cognitive_rebuild.py
 â”œâ”€â”€ feeds/
 â”‚    â”œâ”€â”€ rss_processor.py
 â”‚    â””â”€â”€ pdf_reader.py
 â”œâ”€â”€ ui/
 â”‚    â”œâ”€â”€ dashboard.py
 â”‚    â””â”€â”€ emotion_engine.py
 â”œâ”€â”€ devmode/
 â”‚    â”œâ”€â”€ executor.py
 â”‚    â””â”€â”€ sandbox.py
 â””â”€â”€ models/
       â”œâ”€â”€ sue.gguf            (place your chat model here)
       â””â”€â”€ embedding.gguf      (place embedding model here)

ğŸ› ï¸ Installation (Ubuntu)

Clone or unzip SUE, then run:

chmod +x install.sh
./install.sh


This installs:

Python dependencies

llama-cpp-python backend

Systemd service

Autostart + autorestart

âš™ï¸ Running SUE
Start manually
python3 sue.py

Start as system service
sudo systemctl start sue

Stop
sudo systemctl stop sue

Restart
sudo systemctl restart sue

View live logs
journalctl -u sue -f

ğŸ§© Model Setup

Place your GGUF models here:

models/sue.gguf
models/embedding.gguf

Recommended Models

Chat model: MythoMax-L2-13B-GGUF

Embedding model: nomic-embed-text-v1-GGUF or any embed-capable GGUF

ğŸ—‚ï¸ Configuring SUE
config/settings.json

Controls:

model paths

memory paths

RSS settings

TTS provider

DevMode options

Example:

{
  "model_path": "models/sue.gguf",
  "embedding_model": "models/embedding.gguf",
  "input_mode": "text",
  "rss": { "enabled": true, "digest_on_start": true }
}

config/feeds.json

Add or remove RSS feeds:

{
  "default_feeds": [
    "https://feeds.bbci.co.uk/news/rss.xml"
  ]
}

ğŸ§ª Dev Mode

Trigger DevMode with:

dev <command>


Shell example:

dev ls -la


Python example:

dev py x = 5; y = x * 10

ğŸ’¤ Cognitive Rebuild Mode

Trigger manually:

good night


SUE will:

compress memory

clean logs

set timestamp

rebuild index

ğŸ”’ Privacy & Security

SUE is:

Completely local

Never sends data out

Uses no external APIs

Stores all memory offline

Fully transparent

Open-source and auditable

ğŸ§˜ Credits

Created by:
ğŸ›¡ï¸ Jedi Security
Built for autonomy, privacy, and raw capability.

â¤ï¸ License

MIT License â€” free to modify, expand, and redistribute.


